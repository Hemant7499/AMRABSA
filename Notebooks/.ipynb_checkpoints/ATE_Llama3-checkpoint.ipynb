{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d7dd58-124c-4a33-836f-4325de4d4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "root_path = '/home/askohli2/InstructABSA'\n",
    "    \n",
    "use_mps = True if torch.torch.backends.mps.is_built() else False\n",
    "os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f23afc9-3720-4983-8c7d-f1e7a4266f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "from InstructABSA.data_prep import DatasetLoader\n",
    "from InstructABSA.utils import T5Generator, T5Classifier\n",
    "from instructions import InstructionsHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d00377-813f-4c72-8d8e-7bb2bae1db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Name:  lapt2014_iabsa1\n",
      "Model output path:  ./Models/ate/allenaitk-instruct-base-def-pos-lapt2014_iabsa1\n"
     ]
    }
   ],
   "source": [
    "task_name = 'ate'\n",
    "experiment_name = 'lapt2014_iabsa1'\n",
    "model_checkpoint = 'allenai/tk-instruct-base-def-pos'\n",
    "print('Experiment Name: ', experiment_name)\n",
    "model_out_path = './Models'\n",
    "model_out_path = os.path.join(model_out_path, task_name, f\"{model_checkpoint.replace('/', '')}-{experiment_name}\")\n",
    "print('Model output path: ', model_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbdef6e-421d-4436-9978-6a42411f6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "id_train_file_path = './Dataset/SemEval14/Train/Laptops_Train.csv'\n",
    "id_test_file_path = './Dataset/SemEval14/Test/Laptops_Test.csv'\n",
    "id_tr_df = pd.read_csv(id_train_file_path)\n",
    "id_te_df = pd.read_csv(id_test_file_path)\n",
    "\n",
    "# Get the input text into the required format using Instructions\n",
    "instruct_handler = InstructionsHandler()\n",
    "\n",
    "# Set instruction_set1 for InstructABSA-1 and instruction_set2 for InstructABSA-2\n",
    "instruct_handler.load_instruction_set1()\n",
    "\n",
    "# Set bos_instruct1 for lapt14 and bos_instruct2 for rest14. For other datasets, modify the insructions.py file.\n",
    "loader = DatasetLoader(id_tr_df, id_te_df)\n",
    "if loader.train_df_id is not None:\n",
    "    loader.train_df_id = loader.create_data_in_ate_format(loader.train_df_id, 'term', 'raw_text', 'aspectTerms', instruct_handler.ate['bos_instruct1'], instruct_handler.ate['eos_instruct'])\n",
    "if loader.test_df_id is not None:\n",
    "    loader.test_df_id = loader.create_data_in_ate_format(loader.test_df_id, 'term', 'raw_text', 'aspectTerms', instruct_handler.ate['bos_instruct1'], instruct_handler.ate['eos_instruct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "008294c6-c41d-4006-a747-be1612339835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447e1e5e8b4e47b881d61ab02e3a8fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef4c4c795f1409f924e7f11d123d0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create T5 utils object\n",
    "t5_exp = T5Generator(model_checkpoint)\n",
    "\n",
    "# Tokenize Dataset\n",
    "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n",
    "\n",
    "# Training arguments\n",
    "training_args = {\n",
    "    'output_dir':model_out_path,\n",
    "    'evaluation_strategy':\"no\",\n",
    "    'learning_rate':5e-5,\n",
    "    'lr_scheduler_type':'cosine',\n",
    "    'per_device_train_batch_size':8,\n",
    "    'per_device_eval_batch_size':16,\n",
    "    'num_train_epochs':4,\n",
    "    'weight_decay':0.01,\n",
    "    'warmup_ratio':0.1,\n",
    "    'save_strategy':'no',\n",
    "    'load_best_model_at_end':False,\n",
    "    'push_to_hub':False,\n",
    "    'eval_accumulation_steps':1,\n",
    "    'predict_with_generate':True,\n",
    "    'use_mps_device':use_mps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d857272-ae7c-4005-87e1-df2f1e29cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer device: cuda:0\n",
      "\n",
      "Model training started ....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1524' max='1524' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1524/1524 03:05, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.564800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.202000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_trainer = t5_exp.train(id_tokenized_ds, **training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c33bb6-f95e-476f-b0af-613ec3486c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "id_train_file_path = './Dataset/SemEval14/Train/Laptops_Train.csv'\n",
    "id_test_file_path = './Dataset/SemEval14/Test/Laptops_Test.csv'\n",
    "id_tr_df = pd.read_csv(id_train_file_path)\n",
    "id_te_df = pd.read_csv(id_test_file_path)\n",
    "\n",
    "# Get the input text into the required format using Instructions\n",
    "instruct_handler = InstructionsHandler()\n",
    "\n",
    "# Set instruction_set1 for InstructABSA-1 and instruction_set2 for InstructABSA-2\n",
    "instruct_handler.load_instruction_set1()\n",
    "\n",
    "# Set bos_instruct1 for lapt14 and bos_instruct2 for rest14. For other datasets, modify the insructions.py file.\n",
    "loader = DatasetLoader(id_tr_df, id_te_df)\n",
    "if loader.train_df_id is not None:\n",
    "    loader.train_df_id = loader.create_data_in_ate_format(loader.train_df_id, 'term', 'raw_text', 'aspectTerms', instruct_handler.ate['bos_instruct1'], instruct_handler.ate['eos_instruct'])\n",
    "if loader.test_df_id is not None:\n",
    "    loader.test_df_id = loader.create_data_in_ate_format(loader.test_df_id, 'term', 'raw_text', 'aspectTerms', instruct_handler.ate['bos_instruct1'], instruct_handler.ate['eos_instruct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a6a67d-0dc2-4ec4-8d0f-5968b4777fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ca852060df401396b78cd960f9d9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cf1cd52c3d4c7abce1e26e2ff38bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "T5Generator.get_labels() got an unexpected keyword argument 'trained_model_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m id_ds, id_tokenized_ds, ood_ds, ood_tokenzed_ds \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mset_data_for_training_semeval(t5_exp\u001b[38;5;241m.\u001b[39mtokenize_function_inputs)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Get prediction labels - Training set   \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m id_tr_pred_labels \u001b[38;5;241m=\u001b[39m \u001b[43mt5_exp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mid_tokenized_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_model_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_out_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m id_tr_labels \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m id_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Get prediction labels - Testing set\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: T5Generator.get_labels() got an unexpected keyword argument 'trained_model_path'"
     ]
    }
   ],
   "source": [
    "# Model inference - Loading from Checkpoint\n",
    "t5_exp = T5Generator(model_out_path)\n",
    "\n",
    "# Tokenize Datasets\n",
    "id_ds, id_tokenized_ds, ood_ds, ood_tokenzed_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n",
    "\n",
    "# Get prediction labels - Training set   \n",
    "id_tr_pred_labels = t5_exp.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'train', trained_model_path = model_out_path, batch_size = 16)\n",
    "id_tr_labels = [i.strip() for i in id_ds['train']['labels']]\n",
    "\n",
    "# Get prediction labels - Testing set\n",
    "id_te_pred_labels = t5_exp.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', trained_model_path = model_out_path, batch_size = 16)\n",
    "id_te_labels = [i.strip() for i in id_ds['test']['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbf3da-8f7a-434a-9be2-46eef450ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, f1 = t5_exp.get_metrics(id_tr_labels, id_tr_pred_labels)\n",
    "print('Train Precision: ', p)\n",
    "print('Train Recall: ', r)\n",
    "print('Train F1: ', f1)\n",
    "\n",
    "p, r, f1 = t5_exp.get_metrics(id_te_labels, id_te_pred_labels)\n",
    "print('Test Precision: ', p)\n",
    "print('Test Recall: ', r)\n",
    "print('Test F1: ', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
